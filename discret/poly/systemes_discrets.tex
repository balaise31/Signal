\chapter{Systèmes discrets}
\def\y{\vec{y}}
\def\x{\vec{x}}
\def\h{\vec{h}}
\def\g{\vec{g}}
\def\d0{\vec{\delta_0}}


L'analogie entre systèmes continus et discrets est forte, nous
proposons ici de revenir sur les systèmes continus et d'aborder les
systèmes discrets avec une approche commune par calcul opérationnel.


\imagetexte{0.3}{op_sys}{0.6}{ Un système (conintu ou discret) est vu
  comme un opérateur G transformant un signal $\x$ d'un espace de
  signaux $E$ en un signal $\y$ du même espace. L'automaticienne
  associera un schéma-bloc (en rose les signaux et espaces de signaux,
  en noir les systèmes) à cet opérateur transformant un signal en
  signal.}

Nous nous limitons dans ce chapitre aux systèmes à simple entrée et simple sortie~:

\begin{definition}{Système SISO (Single Input Single Output)}
  
  Un système discret SISO est une application qui associe à un signal
  d'entré $\x$ un signal de sortie unique $\y$. Les signaux $\x$ et $\y$
  sont des fonctions prises dans un espace le plus général possible noté
  ici $E$. Ce qui donne pour un système SISO discret nommé $G$~:
  \begin{equation}
    G : \qquad \application{E}{E}{\x}{\quad \y} 
    % DONE : correction TYPAGE et remarque notation
  \end{equation}

\end{definition}

Les signaux peuvent être des fonctions de la variable réelle continue
ou discrète, prenant des valeurs réelles, complexes voire
composite. La \tabref{tab:espaces_signaux} liste les principaux
espaces de signaux.

\begin{table}[!ht]
  \begin{tabular}{p{0.1\textwidth}|c|c}
   Espaces  & à variable continue    & à variable discrète  \\\hline
    fonction réelle & $E=\R^\R,\quad f\in E $  &  $E=\R^\Z,\quad f\in E $   \\
            & $ f:\application{\R}{\R}{t}{f(t)} $   &  $\application{\Z}{\R}{k}{f\b{k}} $   \\
    \hline
        fonction complexe & $E=\C^\R$   &    $E=\C^\Z$  \\
    & $f:\application{\R}{\C}{t}{f(t)} $   &    $f:\application{\Z}{\C}{k}{f\b{k}} $     \\
    \hline
        image réelle & $E=\R^{\R^2}$   &   $E=\R^{\Z^2}$\\     
    & $f:\application{\R^2}{\R}{\p{x,y}}{f(x,y)} $   &   $f:\application{\Z^2}{\R}{\p{l,k}}{f\b{l,k}}$      \\
    \hline
       image  couleur & $E={\R^3}^{\R^2}$   &   $E={\R^3}^{\Z^2}$      \\
    & $f:\application{\R^2}{\R^3}{\p{x,y}}{f\p{x,y}=\vvvect{r\p{x,y}}{v\p{x,y}}{b\p{x,y}}} $   &   $f:\application{\Z^2}{\R^3}{\p{l,k}}{f\b{l,k}=\vvvect{r\b{l,k}}{v\b{l,k}}{b\b{l,k}}}$      \\
\hline
  \end{tabular}
  \caption{Les différents espaces de signaux continus et discets de différents types de scalaires ($\R$ et $\C$) et différentes dimentions.}
  \label{tab:espaces_signaux}
\end{table}

\begin{remarque}
  On choisit des notations permettant de distinguer clairement~:
  \begin{itemize}
  \item un signal $\vec{f}$  et une variable $f$~;
  \item une valeur $f\p{\nu}$ d'un signal $f$ continu évalué à un instant $\nu\in\R$ et une valeur $f\b{\nu}$ pour un signal discret pris à l'instant $\nu\in\N$. Dans le cas d'une période d'échantillonnage notée $T_e$ on notera donc $f\b{k}=f\p{k.T_e}$~;
   \item une image de $x$ par l'application $f$ est notée $f\p{x}$ alors que l'image d'un signal $\x$ par l'opérateur $F$ est notée $F\OperDe{\x}$. Une application de la variable réelle ou entière est généralement appelée \emph{fonction} alors qu'une application de fonction en fonction est appelée \emph{opérateur}. 
  \end{itemize}
\end{remarque}
\section{Systèmes linéaires}


La classe des systèmes linéaires est fondamentale car elle offre de
nombreux outils et propriétés mathématiques.

\begin{definition}{Système linéaire}
  \label{def:linearite}

  \def\xu{\vec{x_1}}
  \def\xd{\vec{x_2}}

  Un système est dit linéaire si, et seulement si, l'application $G$
  associée est linéaire, soit pour tout
  $\p{\xu, \xd, \lambda} \in E^2 \times \R$~:
  \begin{eqnarray}
    \label{eq:def_linearite}
    G\b{\xu + \lambda\, \xd} = G\b{\xu}(t) + \lambda\,G\b{\xd}
  \end{eqnarray}
\end{definition}

Ce qui donne pour l'automaticienne en schéma-bloc~:

\graphe{0.75\textwidth}{op_lineaire}

Une des conséquences de la linéarité est la possibilité d'appliquer le
principe de superposition cher à l'électronicienne~: \og{} la réponse
d'un système électronqiue à une combinaison de générateurs est la combinaison des
réponses à chaque générateur.\fg{}

\begin{definition}{Systèmes continus élémentaires}
  \label{def:systeme_elementaires_continus}
  
  Les trois systèmes linéaires élémentaires que nous considérons dans
  l'étude des systèmes linéaires continus sont :
  \begin{description}
  \item[le gain $a.x$]~: $t \mapsto a\,x\p{t}$ où a est une constante
    scalaire réelle ou complexe
  \item[le dérivateur $\oder\b{x}=\oder\circ x$]~:
    $ t \mapsto \dDtDe{x}\p{t} $
  \item[l'intégrateur $\oint\b{x}=\oint\circ x$]~:
    $ t \mapsto \integ{0}{t}{x\p{\nu}\derivDe{\nu}}$
  \end{description}
\end{definition}

On peut aisément vérifier que ces systèmes respectent la condition de
linéarité~\ref{eq:def_linearite}.

\begin{remarque}
  De manière implicite, on choisit un espace de fonction $L_c$ qui est
  stable par toute combinaison de compositions de ces opérateurs (même
  une infinité de compositions de $\oder$ par exemple) soit un espace
  complet de fonctions.

  On aimerait que les opérateurs dérivateur $\oder$ et intégrale
  $\oint$ commutent et soient réciproque sur $L_c$~:
  $\oder\circ\oint=\oint\circ\oder=\Id$. De manière à obtenir une
  composition de ces opérateurs qui ait la même propriété qu'un
  produit algébrique inversible.
  
  Pour que cela soit vrai même avec les fonctions discontinues, il
  faut introduire les distributions de \Dirac{} voir
  \chapref{sec:deriv_discontinues}.
\end{remarque}

\begin{definition}{Systèmes élémentaires discrets}
  
  Dans le cas des systèmes discret, les systèmes élémentaires sont :
  \begin{description}
  \item[le gain $a.x$]~: $ k \mapsto a\,x\b{k}$ où a est une constante
    scalaire réelle ou complexe
  \item[le retard unité $\oret\b{x}=\oret\circ x$]~:
    $ k \mapsto x\b{k-1}$.
  \item[l'avance unité $\oavance\b{x}=\oavance\circ x$]~:
    $ k \mapsto x\b{k+1} $
  \end{description}
\end{definition}

On peut aisément vérifier que ces systèmes respectent la condition de
linéarité~\ref{eq:def_linearite}.

\begin{remarque}
  La commutation et réciprocité des opérateurs retard $\oret$ et
  avance $\oavance$ est évidente et ne pose pas de problème théorique,
  contrairement au cas continus~:
  $\oret\circ\oavance=\oavance\circ\oret=\Id$.

  La composition~$\circ$ de ces opérateurs avec l'opérateur somme de
  systèmes $+$ a donc une structure d'anneau commutatif~: $\circ$ et
  $+$ des systèmes se comporte comme $\times$ et $+$ des nombres
  réels.

  L'espace des signaux $L_e$ (ou des suites complexes) est stable et
  complet par l'application des opérateurs élémentaires.
\end{remarque}

L'opérateur dérivée n'a pas de sens en discret, car la limite
$s'(x)=\lim\limits_{h\to 0} \frac{s(x+h)-s(x)}{h}$ n'aurait pas de
sens pour $h$ entier. On peut s'approcher de cet opérateur avec des
combinasons plus ou moins complexes et précises des opérateurs avance
et retard élémentaires.

\begin{exemple}
  \label{exemple:differentiateur_lineaire}
  L'effet du système \emph{différentiateur} sur le signal d'entrée est
  d'écrit par l'opérateur ~:
  $$L : x \mapsto y=\frac{x-\oret\b{x}}{T_e}$$
  
  Vérifions d'abord que cet opérateur est linéaire~:
  \begin{eqnarray*}
    L\b{x_1+\lambda x_2}\b{k} &= L\b{x_1+\lambda x_2}\b{k}\\
                              &= \frac{x_1\b{k}+\lambda x_2\b{k} - \oret\b{x_1+\lambda x_2}\b{k}}{T_e}\\
                              &= \frac{x_1\b{k}+\lambda x_2\b{k} - \p{x_1\b{k-1}+\lambda x_2\b{k-1}}}{T_e} = A\\
    L\b{x_{1}}\b{k}+\lambda\,L\b{x_{2}}\b{k}  &= \frac{x_1\b{k} - x_1\b{k-1}}{T_e}+\lambda\,\frac{x_2\b{k} - x_2\b{k-1}}{T_e}=A
  \end{eqnarray*}
  Le système est donc linéaire.
\end{exemple}


% \begin{remarque}
%   Pour résoudre les complexes équations différentielles des
%   télégraphistes, \Heaviside{} utilise ces opérateurs de base et
%   introduit le \emph{calcul opérationnel}. Cela consiste à
%   représenter l'application de l'opérateur dérivée sur une fonction
%   $f$ comme une simple multiplication par un nombre $p$. Ainsi une
%   équation différentielle $a\,y'' + 2y' -y = 3\int x$ est associée à
%   l'équation symbolique $a\,p^2\,y + 2\,p\,y - y = \frac{3}{p}x$. Il
%   est alors possible de résoudre algébriquement l'équation sous
%   forme de fractions rationnelles ce qui donnerait avec notre
%   exemple~: $y = \frac{3/p}{a\,p^2+2p+1} x$. Rappelons que $x$ et
%   $y$ sont des fonctions et non des réels et que dans ce cas les
%   opérations ne sont pas de simple multiplication et addition de
%   réels mais bien des multiplications et additions de fonctions. La
%   variable symbolique $p$ est utilisée comme un nombre réel mais
%   n'est en aucun cas un réel...
% \end{remarque}

\section{Systèmes invariants}
Il est fréquent, et surtout théoriquement utile, qu'un système
réagisse de la même manière indépendemment de l'instant où est
appliqué le signal d'entrée. Ce qui conduit à la définition suivante~:

\begin{definition}{Système invariant dans le temps}

  Un système discret (resp. continu) est dit invariant dans le temps
  si et seulement si son application associée $L$ (resp. $L_c$)
  vérifie~:
  \begin{eqnarray}
    \forall x\in L_E, \forall (k,k_0)\in \N^2, \quads L[k\mapsto x(k-k_{0})] = L[x](k-k_{0}) \\
    \forall x\in L_E, \forall (t,t_0)\in \R^2, \quads L_c[t\mapsto x(t-t_{0})] = L[x](t-t_{0}) 
  \end{eqnarray}
  
  En terme d'opérateur~; un système $L$ est invariant dans le temps
  si, et seulement si, son opérateur commute avec tout opérateur
  retard de $k_0$ noté
  $\oretDe{k_0}=\oret^{k_0}\b{x}= k\mapsto x\b{k-k_0}$~:
  \begin{eqnarray}
    \label{eq:sys_invariant}
    L\circ\oretDe{k_0} \; = \; \oretDe{k_0}\circ L  \qquad \iff \qquad  L\b{\oretDe{k_0}\b{x}} = \oretDe{k_0}\b{L\b{x}}
    \\
    L_c\circ\oretDe{\tau} \; = \; \oretDe{\tau}\circ L_c  \qquad \iff \qquad  L_c\b{\oretDe{\tau}\b{x}} = \oretDe{\tau}\b{L_c\b{x}}
  \end{eqnarray}
\end{definition}

Autrement dit \og{}la réponse du système à un signal retardé est le
retard de la réponse du système.\fg{}~; ou encore \og{} la réponse du
système ne dépend pas de l'origine des temps choisie.\fg{}


%% TODO lien vers causalité.

\begin{remarque}
  Il est facile de vérifier que les systèmes discrets élémentaires que
  sont le gain~; le retard unitaire et l'avance unitaire (gain,
  dérivateur et intégrateur pour le continu) sont invariants.  Il en
  est de même pour tout système constitué de combinaisons linéaires et
  de composition de systèmes élémentaires.
  
  Il suffit alors de montrer que le système se décompose avec des
  \emph{coefficients constants} avec des systèmes élémentaires en le
  mettant sous forme \emph{d'équation aux différences} ou
  \emph{récurrence} à coefficients constants (\emph{equations
    différentielle} en continu) ou en un schéma bloc à coefficients
  constant.
\end{remarque}


\section{Réponse d'un système LTI}
Rappelons qu'un système peut aussi bien représenter un correcteur dans
une boucle d'asservissement, qu'un filtre utilisé en boucle ouverte,
ou bien un modèle de système à commander ou observer~: calculer la
réponse d'un système à un signal, c'est aussi \og{}faire du
filtrage.\fg{}

Nous allons d'abord montrer que l'opération de filtrage consiste en
temporel à effectuer une convolution du signal d'entré $x$ avec la
réponse impulsionnelle $h$ du système $H$ ainsi défini.

En un second temps nous utiliserons la réponse impulsionnelle pour
caractériser la propriété de stabilité du système.

Nous terminerons en montrant que l'opération duale du filtrage
temporel est un \emph{fenêtrage fréquentiel} ou multiplication par la
transformée de la réponse impulsionnelle $\TZ\p{h}=\TZlui{H}$.

\subsection{Réponse impulsionnelle}
\label{sec:rip}
Dans le cas discret, l'obtention de la réponse d'un système est facile
à obtenir en utilisant les propriétés LTI du système $H$ et en
décomposant le signal d'entré $x$ dans la base temporelle canonique.


Contrairement au cas continu, un signal d'entrée quelconque $x$ se
décompose facilement en impulsions unité (voir la base temporelle de
$\RN$ dans \secref{sec:RN}). La \figref{fig:reponse_convolution}
reprend la décomposition en impulsions d'un signal d'entré
$s=k\mapsto \somme{j\in\Z}{}{s[j].d_j\ded{k}}$ et applique un système
$H$ de réponse impulsionnelle $h$ à chaque impulsion pour obtenir la
réponse $y$ du système.

\begin{figure}[ht!]
  \centering \graphe{0.9\textwidth}{reponse_convolution}
  \caption{La réponse d'un système linéaire invariant $y$ est la somme
    des réponses impulsionnelles des impulsions qui composent le
    signal d'entré $s$.}
  \label{fig:reponse_convolution}
\end{figure}

On retrouve ainsi la formule de convolution temporelle de
$y=s\conv h$. Le résultat est démontré dans l'équation
\eqref{eq:reponse_convolution} en utilisant les propriétés de
linéarité et invariance du système.


\begin{align}
  \label{eq:reponse_convolution}
  \caCest{x = \somme{j=-\infty}{\infty}{x\b{j}\delta_{j}}}{\text{signal}}\quad \implies\quad &y=H\b{x}=H\b{\somme{j=-\infty}{\infty}{x\b{j}\delta_{j}}} \nonumber\\
  \underset{\text{linéarité de H}}{\implies}\quad &y=\somme{j=-\infty}{\infty}{H\b{ \;\caCest{x\!\!\b{j}}{\text{constante !}}\delta_{j}\;}} \underset{\text{linéarite de H}}{=} \;\;\somme{j=-\infty}{\infty}{x\!\b{j}\caCest{H\b{\delta_j}}{H.\oret^j\b{\delta_0}}} \nonumber \\
  \implies \quad &y=\somme{j=-\infty}{\infty}{x\b{j}.H\compo\oret^j\!\b{\delta_{0}}} \underset{\text{invariance de H}}{=} \;\;\somme{j=-\infty}{\infty}{x\b{j}.\oret^j\compo\caCest{H\b{\delta_{0}}}{h}}\nonumber\\
  \implies \quad & y= \somme{j=-\infty}{\infty}{x\b{j}.\caCest{\oret^j\b{h}}{k\mapsto h\b{k-j}}}=x\conv h \nonumber\\
  \implies \quad & \forall k\in\Z,\quad  y\b{k}= \somme{j=-\infty}{\infty}{x\b{j}\,h\!\b{k-j}} = x\conv h\b{k}
\end{align}
où l'opérateur $\conv$ est la convolution discrète définie ci-après.

\begin{definition}{Convolution discrète}
  \label{def:convolution_discrete}
  
  La convolution de signaux discrets $u$ et $v$ notée $u\conv v$ est le
  signal discret défini par~:
  \begin{align}
    \label{eq:convolution_discrete}
    &u\conv v \quad &:& \quad k \mapsto u\conv v\b{k} =\somme{j=-\infty}{\infty}{u\ded{j}.v\ded{k-j}} &\underset{j\leftrightarrow j+k}{=}&  \somme{j=-\infty}{\infty}{u\ded{j+k}.v\ded{-j}} \nonumber\\
    &u\conv v \quad & = &\quad\scald{u}{\caCest{\conj{\oret^k.\,\Sy\ded{v}}}{\conj{j\mapsto v\ded{k-j}}}} &=& \scald{\oret^{-k}\ded{u}}{\conj{\Sy\ded{v}}} 
  \end{align}
  où $\oret^k$ est le retard de $k$ échantillons et
  $\oret^{-k}=\oavance^k$ son opérateur réciproque (inverse
  algébrique)~: l'avance de $k$ échantillons.
\end{definition}

\begin{remarque}
  \textbf{Attention à l'ordre des opérations~: la symétrie et le
    retard ne commutent pas~!}

  Même si nous avons vu dans \secref{sec:dualite} que les opérateurs
  $\Sy$ et $\F$ commutent~: $\F\circ\Sy=\Sy\circ\F=\Finv$, il n'en est
  pas de même pour les opérateurs $\Sy$ et $\oret$~!

  Prendre un signal $s$ de la variable discrète $j$, l'avancer de $k$
  échantillons avec $\oavance^k=\oret^{-k}$ puis le retourner avec
  $\Sy$ donne
  $$\caCest{\Sy\;\circ}{\text{Symétrie de }}\;\caCest{\oret^{-k}}{\text{avance }\oavance^k}\b{s} = \Sy\b{\caCest{\oret^{-k}\b{s}}{j\mapsto s\ded{j+k}}}\,: j\mapsto s\ded{\caCest{\p{-j}}{\text{symétrie}}+k}=s\ded{k-j}$$

  Alors que prendre un signal, le retourner avec $\Sy$ puis l'avancer
  avec $\oret^{-k}$ donne
  $$\caCest{\oret^{-k}\;\circ}{\text{Avance }\oavance^k\text{ de }}\;\caCest{\Sy}{\text{symétrie}}\b{s}= \oret^{-k}\b{\caCest{\Sy\b{s}}{j\mapsto s\ded{-j}}}\,: j\mapsto s
  \ded{-\caCest{\p{j+k}}{\text{avance}}}=s\ded{-j-k}$$

  On remarque donc que $\oret^{-k}\circ\Sy\neq\Sy\circ\oret^{-k}$. En
  revanche prendre un signal, le retourner avec $\Sy$ puis le
  \emph{retarder} avec $\oret^{k}$ donne
  $$\caCest{\oret^{k}\;\circ}{\text{Retard de }}\;\caCest{\Sy}{\text{symétrie}}\b{s}= \oret^{k}\b{\caCest{\Sy\b{s}}{j\mapsto s\ded{-j}}}\,: j\mapsto s\ded{-\p{j-k}}=s\ded{k-j}$$

  Donc la commutation donne $\Sy\circ\oret^{-k}=\oret^{k}\circ\Sy$,
  autrement dit soit~:

  \emph{ \og{} La symétrie de l'avance d'un signal est le retard de
    son symétrique\fg.}
\end{remarque}

L'analogie avec la convolution de signaux continus $u$ et $v$ notée
$u\conv v$ fonctionne aussi en utilisant le produit scalaire continu
$\scald{u}{\conj{\oret^k.\Sy\b{v}}}$ au lieu du produit scalaire
discret.

\begin{definition}{Convolution continue}
  \begin{align}
    \label{eq:convolution_continue}
    &u\conv v \quad &:& \quad  t \;\mapsto\; u\conv v\de{t} =\integ{x=-\infty}{\infty}{u\de{x}.v\de{t-x}\dx} &=& \integ{t=-\infty}{\infty}{u\de{x+t}.v\de{-x}\dx} \nonumber\\
    &u\conv v & = & \quad \scal{u}{\conj{\oret^k\Sy\b{v}}} &=& \quad\scal{\oret^{-k}\b{u}}{\conj{\Sy\b{v}}} 
  \end{align}
\end{definition}


\section{Stabilité d'un système LTI}
\label{sec:stabilite}
La réponse impulsionnelle (notée \RIP) caractérise entièrement un
système LTI, puisque l'opération de convolution permet d'obtenir la
sortie d'un système pour n'importe quelle entrée.

Nous alons caractériser deux types de stabilité des systèmes LTI à
partir de leur \RIP{}~:
\begin{description}
\item[Stabilité BIBO] (\emph{Borned Imput Borned Output}, il n'y pas
  de sigle Français d'usage courant) associée à la propriété de donner
  des réponses bornées pour toutes entrée bornée~;
\item[Stabilité simple] chère aux automaticiennes qui exprime le fait
  qu'un système relâché (dont l'entrée reste nulle à partir d'un
  instant) retourne vers son état d'équilibre qui, dans le cas de
  systèmes linéaires, correspond à l'état null et à une sortie nulle.
\end{description}

\subsection{Stabilité BIBO}

En pratique, la stabilité BIBO garantit qu'un système numérique puisse
toujours calculer une valeur finie et donc codable à partir d'un
signal réel forcément borné.

\begin{remarque}\remarqueTitre{Notations}
  On rappelle qu'un signal $s$ est borné ssi~:
  $$\exists A\in\R \tq{} \forall k\in \Z, \quad \abs{s\ded{k}}\leq A $$

  On note de manière concise $\abs{x}\leq A$, cette proposition.

  Un signal non borné est, par négation de la proposition, tel que~:
  $$\forall A\in\R, \exists k\in \Z \tq  \abs{s\ded{k}} > A $$

  Cela revient à dire que la suite $\p{s\ded{k}}_{k\in\Z}$ diverge
  vers l'infini (ne pas confondre avec simplement divergente qui est
  la négation de convergente~; par exemple $k\mapsto \sin\ded{k}$ est
  divergente mais non divergente vers l'infini).

  On notera de manière concise $s\to\infty$ le fait que $s$ soit
  non-borné.
  
\end{remarque}

\begin{definition} Un système $H$ est \textbf{stable en entrée bornée
    / sortie bornée} ou \textbf{stable BIBO} ssi pour toute entrée $x$
  bornée la réponse $y=H\b{x}$ du système est bornée~:

  $$\forall x, \quad \abs{x}\leq A \quad\implies\quad \abs{y}\leq B $$
\end{definition}


\begin{theoreme}
  Un système $H$ est stable BIBO si, et seulement si, sa réponse
  impulsionnelle $k\mapsto h\b{k}$ est de module sommable, c.-à-d., la
  série $\left\{h\b{k}\right\}_{k\in\Z}$ est absolument convergente~:
  $$ H \text{ stable BIBO} \iff\sum\limits_{k\in\Z} |h\ded{k}| \in \R$$
\end{theoreme}

La démonstration est intéressante et simple~:

\begin{demo} --- Stabilité BIBO

  
  Nous démontrons l'équivalence pour tout système $H$ de réponse
  impulsionnelle $h$~:
  $$ \sum \abs{h}\in\R \iff \text{stable BIBO} \overset{\Delta}{\iff} \p{\forall x, \;\;\abs{x}<A \implies \abs{y}<B}$$  par
  double implication.
  
  \paragraph{\underline{$\implies$~:}}
  Supposons que $\sum\limits_{k\in\Z} \left|h\ded{k}\right|=C\in\R^+$
  et que $\abs{x}\leq A$~; et montrons que $\abs{y}\leq B$.

  Si l'on écrit la réponse $y$ du système à ce $x$ borné en utilisant
  la convolution \eqref{eq:convolution} et que l'on majore les termes
  par leurs valeurs absolues~:

  \begin{align*}
    y=x\conv{}h &: k\mapsto \somme{j=-\infty}{\infty}{h\ded{j}.x\ded{k-j}} \\
    \forall k\in\Z,\quad y\ded{k} & \leq \somme{j=-\infty}{\infty}{\left|h\ded{j}.x\ded{k-j}\right|} = \somme{j=-\infty}{\infty}{|h\ded{j}|.|x\ded{k-j}|}\\
    \implies  y\ded{k} & \leq \somme{j=-\infty}{\infty}{|h\ded{j}| . A}\quad \text{car x est bornée par A}\\
    \implies  y\ded{k} & \leq \;A.\somme{j=-\infty}{\infty}{|h\ded{j}|} = A.C \in \R^+\quad \text{car h est absoluement sommable}\\
    \implies & \quad\exists B=A.C\in\R^+ \mathrel{}\mid\mathrel{}\quad \forall k\in\Z, \; |y\ded{k}|\leq B \implies \abs{y}\leq B
  \end{align*}

  \paragraph{\underline{$\impliedby$ :}}
  La réciproque est plus astucieuse et s'exprime par~:
  $$\forall h,\quad \underbrace{\p{\forall x,\; \abs{x}\leq A \implies \abs{x\conv h}\leq B}}_{P} \implies \underbrace{\sum|h|\in\R}_{Q}$$
  Il est plus aisé de montrer la contra-posée
  $\overline{Q}\implies\overline{P}$ et donc de supposer que
  $\sum|h|\; DV$ et montrer que $\overline{P}$~:

  $$\exists x \tq \abs{x}\leq A \text{ et } \abs{x\conv h}\to\infty $$
  
  Pour cela nous construisons un signal $x$ tel que, de manière
  arbitraire, la sortie $y$ soit non-bornée pour $k=0$ et valle
  $\sum\abs{h}$ et donc diverge (par hypothèse sur $h$).
  
  En prenant la formule de convolution pour $k=0$, nous cherchons
  $x$ tel que~:
  $$ x\conv h\ded{0}= \somme{j=-\infty}{\infty}{x\ded{j}.h\ded{0-j}} =  \somme{j=-\infty}{\infty}{|h\ded{j}|} = +\infty$$
  
  On montre donc que ce signal existe en prenant
  $x[j]=\frac{\overline{h\ded{-j}}}{\abs{h\ded{-j}}}$ et si
  $h\ded{-j}=0$ alors nous prenons $x\ded{j}=0$.  Ce qui permet de
  conclure la réciproque avec~:
  
  $$\exists x=\frac{\overline{h\ded{-j}}}{\abs{h\ded{-j}}} \tq x\conv h = \somme{j=-\infty}{\infty}{\frac{\overline{h\ded{-j}}}{\abs{h\ded{-j}}}.h\ded{0-j}}= \somme{j=-\infty}{\infty}{\abs{h\ded{-j}}}=+\infty$$

  L'implication et sa réciproque sont donc vraies~: CDFQ.
  
\end{demo}


\section{Stabilité simple}
Lorsque le système discret représente le comportement d'un processus,
l'automaticienne préfère la notion de stabilité simple qui évoque le
fait qu'un système libre (entrée nulle) retourne vers son état
d'équilibre (valeur nulle pour les systèmes linéaires).

\begin{definition} Un système LTI est dit \textbf{simplement stable}
  si pour toute entrée $x$ relâchée (nulle à partir d'un certain rang
  $k_0$) sa réponse tends vers 0 en $+\infty$.

  $$H \text{ stable}\quad\quad \overset{\Delta}{\iff}\quad \quad\forall x,\; \exists k_0 \tq{} \forall k>k_0, \; x\ded{k}=0 \quad\implies\quad y\ded{k} \underset{k\to+\infty}{\longrightarrow} 0  $$
\end{definition}

La encore, on peut déduire cette propriété de stabilité à partir de la
réponse impulsionnelle.

\begin{theoreme}
  Un système LTI est stable simplement si, et seulement si, sa réponse
  impulsionnelle $k\mapsto h\b{k}$ tend vers 0 lorsque $k\to +\infty$.
  
  $$ H \text{ simplement stable} \iff \lim_{k\to+\infty} h\ded{k} = 0 $$
\end{theoreme}


La démonstration se fait en utilisant le produit de convolution et en
passant à la limite~: elle est laissée aux soins de la lectrice.






%%% Local Variables:
%%% mode: latex
%%% TeX-master: "poly_discret"
%%% End:

